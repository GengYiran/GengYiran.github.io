<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <!-- <script type="text/javascript" src="js/js_func.js"></script> -->
  <title>Yiran Geng | 耿逸然</title>
  
  <meta name="author" content="Yiran Geng">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" type="image/png" href="images/icon/icon.jpg">
  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?a4292ca8f2fe5fd7dc6dfd78cc894aab";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
  </script>
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yiran Geng | 耿逸然</name>
              </p>
              <p>
                I am a third year undergraduate student in <a href="https://cfcs.pku.edu.cn/research/turing_program/introduction1/index.htm" target="_blank">Turing class</a> at the <a href="https://eecs.pku.edu.cn/" target="_blank">School of Computer Science</a>, <a href="https://english.pku.edu.cn/" target="_blank">Peking University</a> 
                and a research intern at <a href="https://bigai.ai/" target="_blank">Beijing Institute for General Artificial Intelligence (BIGAI)</a>, working with <a href="https://zsdonghao.github.io" target="_blank">Prof. Hao Dong</a> 
                and <a href="https://www.yangyaodong.com/" target="_blank">Prof. Yaodong Yang</a>. I also had the privilege of working closely with <a href="https://hughw19.github.io/" target="_blank">Prof. He Wang</a>. 
              </p>
              <p style="text-align:center">
                <a href="mailto:gyr@stu.pku.edu.cn">Email</a> &nbsp/&nbsp
                <!-- <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?user=q22ys2QAAAAJ&hl=zh-CN">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/GengYiran/">Github</a>&nbsp/&nbsp
                <a href="https://twitter.com/geng_yiran/">Twitter</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/photo.jpg"><img style="width:80%;max-width:80%" alt="profile photo" src="images/photo.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in reinforcement learning, robotics and computer vision.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
          </tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='malle_image'>
                  <br>
                  <img src='images/PGVP3.png' width="180"></div>
                  <br>
                <img src='images/PGVP3.png' width="180">
              </div>
              <script type="text/javascript">
                function malle_start() {
                  document.getElementById('malle_image').style.opacity = "1";
                }
                function malle_stop() {
                  document.getElementById('malle_image').style.opacity = "0";
                }
                malle_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://sites.google.com/view/pgvp/">
                <papertitle>Learning Part-based Cross-Category Object Manipulation Policy from Point
                  Cloud Observations</papertitle>
              </a>
              <br>
              <a:focus>Haoran Geng*</a:focus>,
              <a:focus>Ziming Li*</a:focus>,
              <a:focus>Yiran Geng</a:focus>,
              <a:focus>Jiayi Chen</a:focus>,
              <a:focus>Hao Dong</a:focus>,
              <a:focus>He Wang</a:focus>
              <br>
              <a href="https://sites.google.com/view/pgvp/">Project Page</a>
              <br>
              <em>CVPR 2023</em>, Under Review
              <p></p>
              
              <p>We introduce a large-scale, part-based, cross-category object manipulation benchmark with tasks in realistic, vision-based settings. </p>
            </td>
          
          </tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='malle_image'>
                  <br>
                  <br>
                  <img src='images/myo2.png' width="180"></div>
                  <br>
                  <br>
                <img src='images/myo2.png' width="180">
              </div>
              <script type="text/javascript">
                function malle_start() {
                  document.getElementById('malle_image').style.opacity = "1";
                }
                function malle_stop() {
                  document.getElementById('malle_image').style.opacity = "0";
                }
                malle_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://sites.google.com/view/myochallenge">
                <papertitle>MyoChallenge: Die reorientation</papertitle>
              </a>
              <br>
              <a:focus>Yiran Geng</a:focus>,
              <a:focus>Boshi An</a:focus>,
              <a:focus>Yifan Zhong</a:focus>,
              <a:focus>Jiaming Ji</a:focus>,
              <a:focus>Yuanpei Chen</a:focus>
              <br>
              <a href="https://sites.google.com/view/myochallenge">Challenge Page</a>
              /
              <a href="https://github.com/PKU-MARL/MyoChallenge">Code</a>
              <br>
              <b>Co-winner in NeurIPS 2022 Challenge Track</b>
              <p></p>
              
              <p>Reconfiguring a die to match desired goal orientations. This task require delicate coordination of various muscles to manipulate the die without dropping it. </p>
            </td>

          </tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='malle_image'>
                  <br>
                  <img src='images/draw_01.gif' width="180"></div>
                  <br>
                <img src='images/draw_01.gif' width="180">
              </div>
              <script type="text/javascript">
                function malle_start() {
                  document.getElementById('malle_image').style.opacity = "1";
                }
                function malle_stop() {
                  document.getElementById('malle_image').style.opacity = "0";
                }
                malle_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://sites.google.com/view/trustdehands/">
                <papertitle>TrustDeHands: A Massively Parallel Benchmark for Safe Dexterous Manipulation</papertitle>
              </a>
              <br>
              <a:focus>Yiran Geng*</a:focus>,
              <a:focus>Jiaming Ji*</a:focus>,
              <a:focus href="https://cypypccpy.github.io/">Yuanpei Chen*</a:focus>,
              <a:focus>Haoran Geng</a:focus>,
              <a:focus>Chenrui Tie</a:focus>,
              <a:focus>Long Yang</a:focus>,
              <a:focus href="https://www.yangyaodong.com/">Yaodong Yang</a:focus>
              <br>
              <a href="https://sites.google.com/view/trustdehands/">Project Page</a>
              <br>
              <em>ICLR 2023</em>, Under Review
              <p></p>
              
              <p>We standardize the safe policy optimization methods for solving novel dexterous manipulation tasks and introduce a unified, highly-optimized, extensible, and comprehensive algorithms reimplementation. </p>
            </td>

          <tr onmouseout="malle_stop()" onmouseover="malle_start()">
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='malle_image'>
                  <img src='images/E2EAfford.png' width="190"></div>
                <img src='images/E2EAfford.png' width="190">
              </div>
              <script type="text/javascript">
                function malle_start() {
                  document.getElementById('malle_image').style.opacity = "1";
                }

                function malle_stop() {
                  document.getElementById('malle_image').style.opacity = "0";
                }
                malle_stop()
              </script>
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2209.12941">
                <papertitle><br>End-to-End Affordance Learning for Robotic Manipulation</papertitle>
              </a>
              <br>
              <a:focus>Yiran Geng*</a:focus>,
              <a:focus>Boshi An*</a:focus>,
              <a:focus>Haoran Geng</a:focus>,
              <a:focus href="https://cypypccpy.github.io/">Yuanpei Chen</a:focus>,
              <a:focus href="https://www.yangyaodong.com/">Yaodong Yang</a:focus>,
              <a:focus href="https://zsdonghao.github.io">Hao Dong</a:focus>
              
              <br>
              <a href="https://arxiv.org/abs/2209.12941">ArXiv</a>
              /
              <a href="https://sites.google.com/view/rlafford/">Project Page</a>
              /
              <a>Code (Coming Soon)</a>
              <br>
              <em>ICRA 2023</em>, Under Review
              
              <p></p>
              <p>In this study, we take advantage of visual affordance by using the contact information generated during the RL training process to predict contact maps of interest. </p>
              
            </td>

          </tr>
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='malle_image'>
                  <img src='images/graspNerf.png' width="190"></div>
                <img src='images/graspNerf.png' width="190">
              </div>
              <script type="text/javascript">
                function malle_start() {
                  document.getElementById('malle_image').style.opacity = "1";
                }

                function malle_stop() {
                  document.getElementById('malle_image').style.opacity = "0";
                }
                malle_stop()
              </script>
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2210.06575">
                <papertitle>GraspNeRF: Multiview-based 6-DoF Grasp Detection for Transparent and Specular Objects Using Generalizable NeRF</papertitle>
              </a>
              <br>
              <a:focus href="https://daiqy.github.io/">Qiyu Dai*</a:focus>,
              <a:focus>Yan Zhu*</a:focus>, 
              <a:focus>Yiran Geng</a:focus>,
              <a:focus>Ciyu Ruan</a:focus>,
              <a:focus href="https://www.researchgate.net/profile/Jiazhao-Zhang-2">Jiazhao Zhang</a:focus>,
              <a:focus href="https://hughw19.github.io/">He Wang</a:focus>

              
              <br>

              <a href="https://arxiv.org/abs/2210.06575">ArXiv</a>
              <br>
                <em>ICRA 2023</em>, Under Review
              <p></p>
              <p>
                We propose a multiview RGB-based 6-DoF grasp detection network, GraspNeRF, that leverages the generalizable neural radiance field (NeRF) to achieve material-agnostic object grasping in clutter.
              </p>
            </td>

          </tr>
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='malle_image'>
                  <br>
                  <img src='images/GenDexGrasp.gif' width="190"></div>
                <br>
                <img src='images/GenDexGrasp.gif' width="190">
              </div>
              <script type="text/javascript">
                function malle_start() {
                  document.getElementById('malle_image').style.opacity = "1";
                }

                function malle_stop() {
                  document.getElementById('malle_image').style.opacity = "0";
                }
                malle_stop()
              </script>
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2210.00722/">
                <papertitle>GenDexGrasp: Generalizable Dexterous Grasping</papertitle>
              </a>
              <br>
              <a:focus>Puhao Li*</a:focus>,
              <a:focus>Tengyu Liu*</a:focus>,
              <a:focus>Yuyang Li</a:focus>,
              <a:focus>Yiran Geng</a:focus>,
              <a:focus href="https://yzhu.io/">Yixin Zhu</a:focus>,
              <a:focus href="https://www.yangyaodong.com/">Yaodong Yang</a:focus>,
              <a:focus href="https://siyuanhuang.com/">Siyuan Huang</a:focus>

              
              <br>
              <a href="https://arxiv.org/abs/2210.00722/">ArXiv</a>
              /
              <a href="https://sites.google.com/view/gendexgrasp/">Project Page</a>
              /
              <a href="https://github.com/tengyu-liu/GenDexGrasp">Code</a>
              <br>
              <em>ICRA 2023</em>, Under Review
              <p></p>
              <p>
                This paper introduces GenDexGrasp, a versatile dexterous grasping method that can generalize to unseen hands.
              </p>
            </td>

          </tr>
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='malle_image'>
                  <br>
                  <img src='images/bidexteroushands.gif' width="190"></div>
                  <br>
                <img src='images/bidexteroushands.gif' width="190">
              </div>
              <script type="text/javascript">
                function malle_start() {
                  document.getElementById('malle_image').style.opacity = "1";
                }

                function malle_stop() {
                  document.getElementById('malle_image').style.opacity = "0";
                }
                malle_stop()
              </script>
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1910.00748">
                <papertitle>Towards Human-Level Bimanual Dexterous Manipulation with Reinforcement Learning</papertitle>
              </a>
              <br>
              <a:focus href="https://cypypccpy.github.io/">Yuanpei Chen</a:focus>,
              <a:focus href="https://tianhaowuhz.github.io/">Tianhao Wu</a:focus>, 
              <a:focus href="https://github.com/Shengjie-bob">Shengjie Wang</a:focus>,
              <a:focus href="https://github.com/waterhorse1">Xidong Feng</a:focus>,
              <a:focus href="https://github.com/jiechuanjiang">Jiechuang Jiang</a:focus>,
              <a:focus>Stephen Marcus McAleer</a>,
              <a:focus>Yiran Geng</a>,
              <a:focus href="https://zsdonghao.github.io">Hao Dong</a:focus>,
              <a:focus href="https://z0ngqing.github.io">Zongqing Lu</a:focus>,
              <a:focus href="http://www.stat.ucla.edu/~sczhu/">Song-chun Zhu</a:focus>,
              <a:focus href="https://www.yangyaodong.com/">Yaodong Yang</a:focus>

              
              <br>
              <a href="https://bi-dexhands.ai/">Project Page</a>
              /
              <a href="https://arxiv.org/abs/2206.08686">ArXiv</a>
              /
              <a href="https://github.com/PKU-MARL/DexterousHands">Code</a>
              <br>
              <em>NeurIPS 2022</em>
              <p></p>
              <p>
                We propose a bimanual dexterous manipulation benchmark (Bi-DexHands) according to literature from cognitive science for comprehensive reinforcement learning research.
              </p>
            </td>

          </tr>
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='malle_image'>
                  <img src='images/2022grasparl.gif' width="190"></div>
                <img src='images/2022grasparl.gif' width="190">
              </div>
              <script type="text/javascript">
                function malle_start() {
                  document.getElementById('malle_image').style.opacity = "1";
                }

                function malle_stop() {
                  document.getElementById('malle_image').style.opacity = "0";
                }
                malle_stop()
              </script>
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2203.02119">
                <papertitle>GraspARL: Dynamic Grasping via Adversarial Reinforcement Learning</papertitle>
              </a>
              <br>
              <a:focus href="https://tianhaowuhz.github.io/">Tianhao Wu*</a:focus>, 
              <a:focus href="https://fangweizhong.xyz/">Fangwei Zhong*</a:focus>,
              <a:focus>Yiran Geng</a>,
              <a:focus href="https://www.yangyaodong.com/">Yaodong Yang</a:focus>,
              <a:focus href="https://cs.pku.edu.cn/info/1085/1331.htm">Yizhou Wang</a:focus>,
              <a:focus href="https://zsdonghao.github.io">Hao Dong</a:focus>
              
              <br>
              <a href="https://arxiv.org/abs/2203.02119">ArXiv</a>
              
              <br>
              <em>Under Review 2023</em>
              <p></p>
              <p>
                This study is the first attempt to formulate the dynamic grasping problem as a “move-and-grasp” game and use adversarial RL to train the grasping policy and object moving strategies jointly.
              </p>

            </td>    

          </tr>
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='malle_image'>
                  <br>
                  <img src='images/safepo.png' width="190"></div>
                  <br>
                <img src='images/safepo.png' width="190">
              </div>
              <script type="text/javascript">
                function malle_start() {
                  document.getElementById('malle_image').style.opacity = "1";
                }

                function malle_stop() {
                  document.getElementById('malle_image').style.opacity = "0";
                }
                malle_stop()
              </script>
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1910.00748">
                <papertitle>SafePO: Safe Policy Optimization</papertitle>
              </a>
              <br>
              <a:focus>Jiamg Ji*</a:focus>, 
              <a:focus>Long Yang*</a:focus>, 
              <a:focus>Yifan Zhong*</a:focus>,
              <a:focus href="https://www.yangyaodong.com/">Yuanpei Chen</a:focus>,
              <a:focus>Yiran Geng</a:focus>,
              <a:focus>Shangding Gu</a:focus>,
              <a:focus href="https://zsdonghao.github.io">Hao Dong</a:focus>
              <a:focus>Zhouchen Lin</a:focus>,
              <a:focus href="https://cs.pku.edu.cn/info/1085/1331.htm">Yizhou Wang</a:focus>,
              <a:focus href="https://www.yangyaodong.com/">Yaodong Yang</a:focus>
              
              <br>
              <a href="https://github.com/PKU-MARL/Safe-Policy-Optimization">Project Page</a>
              /
              <a href="https://github.com/PKU-MARL/Safe-Policy-Optimization">Code</a>
              <br>
              <em>Open Source Project</em>
              <p>
                In this study, we standardize the safe policy optimization methods for solving constrained Markov decision processes and introduce a unified, highly-optimized, extensible, and comprehensive algorithm benchmark named SafePO. 
            </td>
          </tr>
          <td style="padding:20px;width:30%;vertical-align:middle">
            <div class="one">
              <div class="two" id='malle_image'>
                <br>
                <img src='images/YINGCAI2.png' width="190"></div>
                <br>
              <img src='images/YINGCAI2.png' width="190">
            </div>
            <script type="text/javascript">
              function malle_start() {
                document.getElementById('malle_image').style.opacity = "1";
              }
              function malle_stop() {
                document.getElementById('malle_image').style.opacity = "0";
              }
              malle_stop()
            </script>
          </td>
          <td style="padding:20px;width:70%;vertical-align:middle">
            <a href="https://arxiv.org/abs/1910.00748">
              <papertitle>Ministry of Education Talent Program Thesis (Physics Track)</papertitle>
            </a>
            <br>
            <a:focus>Yiran Geng</a:focus>, 
            <a:focus>Haoran Geng</a:focus>, 
            <a:focus>Xintian Dong</a:focus>,
            <a:focus>Yue Meng</a:focus>,
            <a:focus>Xujv Sun</a:focus>,
            <a:focus>Houpu Niu</a:focus>
            
            <br>
            <a href=pdf/YINGCAI.pdf>PDF</a>
            <br>
            <em>Selected as the Outstanding Thesis of the National Physics Forum 2018</em>
            <p>
              During my high school years, I was selected for the Ministry of Education Talent Program and conducted physics research at Nankai University and presenting my thesis at the National Physics Forum 2018.
          </td>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Experience</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="10"><tbody>
          <tr>
            <td style="padding-left:20px;padding-right:20px;width:20%;vertical-align:middle"><img src="images/PKU.png", width="90%"></td>
            <td width="80%" valign="center">
              <strong>Peking University</strong>, China
              <br> 2020.09 - now
              <br> <strong>Undergraduate Student</strong>
              <br> Research Advisor: Prof. <a href="https://zsdonghao.github.io/">Hao Dong</a>
              <br> Academic Advisor: Prof. <a href="https://zhenjiang888.github.io/">Zhenjiang Hu</a>
            </td>
          </tr>
          <tr>
            <td style="padding-left:20px;padding-right:20px;width:20%;vertical-align:middle"><img src="images/Bigai.png", width="90%"></td>
            <td width="80%" valign="center">
              <strong>Beijing Institute for General Artificial Intelligence (BIGAI) </strong>, China
              <br> 2022.05 - now
              <br> <strong>Research Intern</strong>
              <br> Research Advisor: Prof. <a href="https://www.yangyaodong.com/">Yaodong Yang</a> and Prof. <a href="http://www.stat.ucla.edu/~sczhu/">Song-Chun Zhu</a>
            </td>
          </tr>

        </tbody></table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Resent Awards and Honors</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:90%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              
            <td style="padding:0px;width:100%;vertical-align:middle">
              <p>
                2022: Co-winner in NeurIPS 2022 Challenge Track
              </p>
              <p>
                2022: Peking University Research Excellence Award
              </p>
              <p>
                2022: Peking University Dean's Scholarship (15000¥)
              </p>
              <p>
                2022: SenseTime Scholarship (Only 2 in the same age group, 20000¥)
              </p>
              <p>
                2021: Peking University Study Excellence Award
              </p>
              <p>
                2021: Peking University Qinjin Scholarship (10000¥)
              </p>
              <p>
                2021: John Hopcroft Scholarship (3000¥)
              </p>
              <p>
                2021: Ministry of Education Top Talent Program Scholarship (1000¥)
              </p>
              <p>
                2019: Gold Medal in Chinese Physics Olympiad (CPHO)
              </p>
              
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Services</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:90%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              
            <td style="padding:0px;width:100%;vertical-align:middle">

              <p>
                Volunteer: WINE 2020
              </p>
              <p>
                Reviewer: CVPR 2023
              </p>
              
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>

  <script xml:space="preserve" language="JavaScript">
  hideblock('VARS_abs');
  </script>
  <script xml:space="preserve" language="JavaScript">
  hideblock('ICCV2021_SSAD_OSAD_abs');
  </script>
  <script xml:space="preserve" language="JavaScript">
  hideblock('NeurIPS2020_ARML_abs');
  </script>
  <script xml:space="preserve" language="JavaScript">
  hideblock('ICML2020_InfoDrop_abs');
  </script>
  <script xml:space="preserve" language="JavaScript">
  hideblock('CVPR2020_DGAM_abs');
  </script>
</body>

</html>
