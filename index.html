<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <!-- <script type="text/javascript" src="js/js_func.js"></script> -->
  <title>Yiran Geng</title>
  
  <meta name="author" content="Yiran Geng">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" type="image/png" href="images/icon/icon_2.jpg">
  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?a4292ca8f2fe5fd7dc6dfd78cc894aab";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
  </script>
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yiran Geng</name>
              </p>
              <p>
                I am a three-year undergraduate student in <a href="https://cfcs.pku.edu.cn/research/turing_program/introduction1/index.htm" target="_blank">Turing class</a> at the <a href="https://eecs.pku.edu.cn/" target="_blank">School of Computer Science</a>, <a href="https://english.pku.edu.cn/" target="_blank">Peking University</a> 
                and a research intern at <a href="https://bigai.ai/" target="_blank">Beijing Institute for General Artificial Intelligence (BIGAI)</a>, working with <a href="https://zsdonghao.github.io" target="_blank">Prof. Hao Dong</a> 
                and <a href="https://www.yangyaodong.com/" target="_blank">Prof. Yaodong Yang</a>. I also had the privilege of working closely with <a href="https://hughw19.github.io/" target="_blank">Prof. He Wang</a>. 
              </p>
              <p style="text-align:center">
                <a href="mailto:gyr@stu.pku.edu.cn">Email</a> &nbsp/&nbsp
                <!-- <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?user=q22ys2QAAAAJ&hl=zh-CN">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/GengYiran/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/photo.jpg"><img style="width:80%;max-width:80%" alt="profile photo" src="images/photo.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in robotics, reinforcement learning and computer vision.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="malle_stop()" onmouseover="malle_start()">
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='malle_image'>
                  <img src='images/E2EAfford.png' width="190"></div>
                <img src='images/E2EAfford.png' width="190">
              </div>
              <script type="text/javascript">
                function malle_start() {
                  document.getElementById('malle_image').style.opacity = "1";
                }

                function malle_stop() {
                  document.getElementById('malle_image').style.opacity = "0";
                }
                malle_stop()
              </script>
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2209.12941">
                <papertitle><br>End-to-End Affordance Learning for Robotic Manipulation</papertitle>
              </a>
              <br>
              <strong>Yiran Geng*</strong>,
              <a>Boshi An*</a>,
              <a>Haoran Geng</a>,
              <a href="https://cypypccpy.github.io/">Yuanpei Chen</a>,
              <a href="https://www.yangyaodong.com/">Yaodong Yang</a>,
              <a href="https://zsdonghao.github.io">Hao Dong</a>
              <br>
              <em>ICRA 2023</em>, Under Review
              <br>
              <a href="https://arxiv.org/abs/2209.12941">ArXiv</a>
              /
              <a href="https://sites.google.com/view/rlafford/">Project Page</a>
              /
              <a>Code (Coming Soon)</a>
              
              
              <p></p>
              <p>In this study, we take advantage of visual affordance by using the contact information generated during the RL training process to predict contact maps of interest. </p>
              
            </td>
          </tr>
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='malle_image'>
                  <img src='images/jenga.png' width="190"></div>
                <img src='images/jenga.png' width="190">
              </div>
              <script type="text/javascript">
                function malle_start() {
                  document.getElementById('malle_image').style.opacity = "1";
                }

                function malle_stop() {
                  document.getElementById('malle_image').style.opacity = "0";
                }
                malle_stop()
              </script>
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <a href="https://sites.google.com/view/trustdehands/">
                <papertitle>TrustDeHands: A Massively Parallel Benchmark for Safe Dexterous Manipulation</papertitle>
              </a>
              <br>
              <strong>Yiran Geng*</strong>,
              <a>Jiaming Ji*</a>,
              <a href="https://cypypccpy.github.io/">Yuanpei Chen*</a>,
              <a>Haoran Geng</a>,
              <a>Chenrui Tie</a>,
              <a>Long Yang</a>,
              <a href="https://www.yangyaodong.com/">Yaodong Yang</a>
              <br>
              <em>ICLR</em> 2023, Under Review
              <br>
              <a href="https://sites.google.com/view/trustdehands/">Project Page</a>
              /
              <a href="https://openreview.net/forum?id=k2Ml8FGtJZp">OpenReview</a>
              <p></p>
              <p>In this work, we presented TrustDeHands, which is the first benchmark focused on safe dexterous
                manipulation. We standardize the safe policy optimization methods for solving CMDPs and introduce a unified, highly-optimized, extensible, and comprehensive algorithms reimplementation. </p>
            </td>

          </tr>
          <td style="padding:20px;width:30%;vertical-align:middle">
            <div class="one">
              <div class="two" id='malle_image'>
                <img src='images/graspNerf.png' width="190"></div>
              <img src='images/graspNerf.png' width="190">
            </div>
            <script type="text/javascript">
              function malle_start() {
                document.getElementById('malle_image').style.opacity = "1";
              }

              function malle_stop() {
                document.getElementById('malle_image').style.opacity = "0";
              }
              malle_stop()
            </script>
          </td>
          <td style="padding:20px;width:70%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2210.06575">
              <papertitle>GraspNeRF: Multiview-based 6-DoF Grasp Detection for Transparent and Specular Objects Using Generalizable NeRF</papertitle>
            </a>
            <br>
            <a href="https://daiqy.github.io/">Qiyu Dai*</a>,
            <a>Yan Zhu*</a>, 
            <strong>Yiran Geng</strong>,
            <a>Ciyu Ruan</a>,
            <a href="https://www.researchgate.net/profile/Jiazhao-Zhang-2">Jiazhao Zhang</a>,
            <a href="https://hughw19.github.io/">He Wang</a>

            <br>
            <em>ICRA 2023</em>, Under Review
            <br>

            <a href="https://arxiv.org/abs/2210.06575">ArXiv</a>

            <p></p>
            <p>
              We propose a multiview RGB-based 6-DoF grasp detection network, GraspNeRF, that leverages the generalizable neural radiance field (NeRF) to achieve material-agnostic object grasping in clutter.
            </p>
          </td>


          </tr>
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='malle_image'>
                  <br>
                  <img src='images/bidexteroushands.gif' width="190"></div>
                  <br>
                <img src='images/bidexteroushands.gif' width="190">
              </div>
              <script type="text/javascript">
                function malle_start() {
                  document.getElementById('malle_image').style.opacity = "1";
                }

                function malle_stop() {
                  document.getElementById('malle_image').style.opacity = "0";
                }
                malle_stop()
              </script>
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1910.00748">
                <papertitle>Towards Human-Level Bimanual Dexterous Manipulation with Reinforcement Learning</papertitle>
              </a>
              <br>
              <a href="https://cypypccpy.github.io/">Yuanpei Chen*</a>,
              <a href="https://tianhaowuhz.github.io/">Tianhao Wu</a>, 
							<a href="https://github.com/Shengjie-bob">Shengjie Wang</a>,
              <a href="https://github.com/waterhorse1">Xidong Feng</a>,
              <a href="https://github.com/jiechuanjiang">Jiechuang Jiang</a>,
              <a>Stephen Marcus McAleer</a>,
              <strong>Yiran Geng</strong>,
              <a href="https://zsdonghao.github.io">Hao Dong</a>,
              <a href="https://z0ngqing.github.io">Zongqing Lu</a>,
              <a href="http://www.stat.ucla.edu/~sczhu/">Song-chun Zhu</a>,
              <a href="https://www.yangyaodong.com/">Yaodong Yang*</a>

              <br>
              <em>NeurIPS 2022</em>
              <br>
              <a href="https://bi-dexhands.ai/">Project Page</a>
              /
              <a href="https://arxiv.org/abs/2206.08686">ArXiv</a>
              /
              <a href="https://github.com/PKU-MARL/DexterousHands">Code</a>
              <p></p>
              <p>
                We propose a bimanual dexterous manipulation benchmark (Bi-DexHands) according to literature from cognitive science for comprehensive reinforcement learning research.
              </p>
            </td>
          </tr>
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='malle_image'>
                  <br>
                  <img src='images/GenDexGrasp.gif' width="190"></div>
                <br>
                <img src='images/GenDexGrasp.gif' width="190">
              </div>
              <script type="text/javascript">
                function malle_start() {
                  document.getElementById('malle_image').style.opacity = "1";
                }

                function malle_stop() {
                  document.getElementById('malle_image').style.opacity = "0";
                }
                malle_stop()
              </script>
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2210.00722/">
                <papertitle>GenDexGrasp: Generalizable Dexterous Grasping</papertitle>
              </a>
              <br>
              <a>Puhao Li*</a>,
              <a>Tengyu Liu*</a>,
              <a>Yuyang Li</a>,
              <strong>Yiran Geng</strong>,
              <a href="https://yzhu.io/">Yixin Zhu</a>,
              <a href="https://www.yangyaodong.com/">Yaodong Yang</a>,
              <a href="https://siyuanhuang.com/">Siyuan Huang</a>

              <br>
              <em>ICRA 2023</em>, Under Review
              <br>
              <a href="https://arxiv.org/abs/2210.00722/">ArXiv</a>
              /
              <a href="https://sites.google.com/view/gendexgrasp/">Project Page</a>
              /
              <a href="https://github.com/tengyu-liu/GenDexGrasp">Code</a>
              <p></p>
              <p>
                This paper introduces GenDexGrasp, a versatile dexterous grasping method that can generalize to unseen hands.
              </p>
            </td>
          </tr>
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='malle_image'>
                  <img src='images/2022grasparl.gif' width="190"></div>
                <img src='images/2022grasparl.gif' width="190">
              </div>
              <script type="text/javascript">
                function malle_start() {
                  document.getElementById('malle_image').style.opacity = "1";
                }

                function malle_stop() {
                  document.getElementById('malle_image').style.opacity = "0";
                }
                malle_stop()
              </script>
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2203.02119">
                <papertitle>GraspARL: Dynamic Grasping via Adversarial Reinforcement Learning</papertitle>
              </a>
              <br>
              <a href="https://tianhaowuhz.github.io/">Tianhao Wu*</a>, 
              <a href="https://fangweizhong.xyz/">Fangwei Zhong*</a>,
              <strong>Yiran Geng</strong>,
              <a href="https://www.yangyaodong.com/">Yaodong Yang</a>,
              <a href="https://cs.pku.edu.cn/info/1085/1331.htm">Yizhou Wang</a>,
              <a href="https://zsdonghao.github.io">Hao Dong</a>
              <br>
              <em>Under Review 2023</em>
              <br>
              <a href="https://arxiv.org/abs/2203.02119">ArXiv</a>
              <p></p>
              <p>
                This study is the first attempt to formulate the dynamic grasping problem as a “move-and-grasp” game and use adversarial RL to train the grasping policy and object moving strategies jointly.
              </p>

            </td>            
          </tr>
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='malle_image'>
                  <br>
                  <img src='images/safepo.png' width="190"></div>
                  <br>
                <img src='images/safepo.png' width="190">
              </div>
              <script type="text/javascript">
                function malle_start() {
                  document.getElementById('malle_image').style.opacity = "1";
                }

                function malle_stop() {
                  document.getElementById('malle_image').style.opacity = "0";
                }
                malle_stop()
              </script>
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1910.00748">
                <papertitle>SafePO: Safe Policy Optimization</papertitle>
              </a>
              <br>
              <a>Jiamg Ji*</a>, 
              <a>Long Yang*</a>, 
              <a>Yifan Zhong*</a>,
              <a href="https://www.yangyaodong.com/">Yuanpei Chen</a>,
              <strong>Yiran Geng</strong>,
              <a>Shangding Gu</a>,
              <a href="https://zsdonghao.github.io">Hao Dong</a>
              <a>Zhouchen Lin</a>,
              <a href="https://cs.pku.edu.cn/info/1085/1331.htm">Yizhou Wang</a>,
              <a href="https://www.yangyaodong.com/">Yaodong Yang</a>
              <br>
              <em>Open Source Project</em>
              <br>
              <a href="https://github.com/PKU-MARL/Safe-Policy-Optimization">Project Page</a>
              /
              <a href="https://github.com/PKU-MARL/Safe-Policy-Optimization">Code</a>
              <p>
                In this study, we standardize the safe policy optimization methods for solving constrained Markov decision processes and introduce a unified, highly-optimized, extensible, and comprehensive algorithm benchmark named SafePO. 
            </td>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Experience</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="10"><tbody>
          <tr>
            <td style="padding-left:20px;padding-right:20px;width:20%;vertical-align:middle"><img src="images/PKU.png", width="90%"></td>
            <td width="80%" valign="center">
              <b>Peking University</b>, China
              <br> 2020.09 - now
              <br>
              <br> <b>Undergraduate Student</b>
              <br> Advisor: Prof. <a href="https://zsdonghao.github.io/">Hao Dong</a>
            </td>
          </tr>
          <tr>
            <td style="padding-left:20px;padding-right:20px;width:20%;vertical-align:middle"><img src="images/Bigai.png", width="90%"></td>
            <td width="80%" valign="center">
              <b>Beijing Institute for General Artificial Intelligence (BIGAI) </b>, China
              <br> 2022.05 - now
              <br>
              <br> <b>Research Intern </b>
              <br> Advisor: Prof. <a href="https://www.yangyaodong.com/">Yaodong Yang</a>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Resent Awards and Honors</heading>
              <p>
                2019: Gold Medal in Chinese Physics Olympiad (CPHO)
              </p>
              <p>
                2021: John Hopcroft Scholarship
              </p>
              <p>
                2021: Peking University Qinjin Scholarship
              </p>
              <p>
                2021: Peking University Study Excellence Award
              </p>
              <p>
                2022: Shangtang Scholarship (Only 2 in the same age group)
              </p>
              <p>
                2022: Peking University Dean's Scholarship
              </p>
              <p>
                2022: Peking University Research Excellence Award
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>

  <script xml:space="preserve" language="JavaScript">
  hideblock('VARS_abs');
  </script>
  <script xml:space="preserve" language="JavaScript">
  hideblock('ICCV2021_SSAD_OSAD_abs');
  </script>
  <script xml:space="preserve" language="JavaScript">
  hideblock('NeurIPS2020_ARML_abs');
  </script>
  <script xml:space="preserve" language="JavaScript">
  hideblock('ICML2020_InfoDrop_abs');
  </script>
  <script xml:space="preserve" language="JavaScript">
  hideblock('CVPR2020_DGAM_abs');
  </script>
</body>

</html>
